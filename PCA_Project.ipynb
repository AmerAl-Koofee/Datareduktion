{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import umap\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Pearson correlation coefficient\n",
    "correlation = df['Floor_area'].corr(df['Price_in_taka'])\n",
    "\n",
    "# Print the result\n",
    "print(f\"Pearson correlation coefficient between Floor_area and Price_in_taka: {correlation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot with a regression line\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(x='Floor_area', y='Price_in_taka', data=df, scatter_kws={'s': 50}, line_kws={'color': 'red'})\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Floor Area (sq ft)')\n",
    "plt.ylabel('Price in Taka')\n",
    "plt.title('Scatter Plot with Regression Line: Floor Area vs Price in Taka')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data, excluding the 'City' column\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df.iloc[:, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA with 2 component\n",
    "pca = PCA(n_components=2)\n",
    "pca = pca.fit(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the component's loadings\n",
    "loadings = pca.components_\n",
    "loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames for better readability\n",
    "loadings = pd.DataFrame(loadings.T, index=df.columns[:-1], columns=[f'PC{i+1}' for i in range(2)])\n",
    "\n",
    "loadings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loadings (eigenvectors) associated with each principal component will show you how much each original feature contributes to the component.\n",
    "\n",
    "The larger the absolute value of the loading, the more the feature contributes to that principal component.\n",
    "\n",
    "The loading value for each feature can be positive or negative, indicating the direction of the contribution.\n",
    "\n",
    "The magnitude of the loading (the absolute value) indicates the strength of the contribution.\n",
    "\n",
    "Features with higher absolute values have a greater impact on the first principal component.\n",
    "\n",
    "PC1:\n",
    "\n",
    "Floor_area (0.534366) and Bathrooms (0.531761) have the highest loadings, meaning they contribute the most to the variance captured by the first principal component.\n",
    "\n",
    "Price_in_taka (0.491189) also contributes significantly but slightly less than the first two.\n",
    "\n",
    "Bedrooms (0.436367) has the lowest loading among the four features, indicating it has the least influence on this principal component, though it still contributes significantly.\n",
    "\n",
    "PC2:\n",
    "\n",
    "Bedrooms has a strong positive loading on PC2, meaning it contributes significantly to this component.\n",
    "\n",
    "Price_in_taka has a strong negative loading, indicating an inverse relationship with PC2.\n",
    "\n",
    "Floor_area also has a negative loading but is less significant compared to Price_in_taka.\n",
    "\n",
    "Bathrooms has a smaller positive loading, suggesting it has a minor influence on PC2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the loadings\n",
    "plt.figure(figsize=(8, 6))\n",
    "loadings.plot(kind='bar', color=['skyblue','red'])\n",
    "plt.title('Feature Loadings for the Principal Component')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Loading')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance = pca.explained_variance_ratio_\n",
    "explained_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The explained_variance will show you how much of the total variance is explained by each principal component.\n",
    "\n",
    "Components with higher explained variance are more important in capturing the overall variability in the data.\n",
    "\n",
    "PC1 (67.57%): The first principal component explains 67.57% of the total variance in your data. \n",
    "\n",
    "This means that PC1 is capturing the majority of the information in your dataset.\n",
    "\n",
    "PC2 (18.35%): The second principal component explains an additional 18.35% of the variance.\n",
    "\n",
    "Combined with PC1, these two components capture about 85.92% of the total variance(Information), which is quite substantial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames for better readability\n",
    "explained_variance = pd.DataFrame(explained_variance, index=[f'PC{i+1}' for i in range(2)], columns=['Explained Variance'])\n",
    "\n",
    "explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_pca =pca.transform(df_scaled)\n",
    "transform_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the 2D projection\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(transform_pca[:, 0], transform_pca[:, 1], c='skyblue', edgecolor='k', s=50)\n",
    "plt.title('2D PCA Projection of the Dataset')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the data points are clustered on the left side of the plot, particularly around the origin, indicating that for these data points, \n",
    "\n",
    "both principal components do not deviate significantly from the mean.\n",
    "\n",
    "There are a few outliers, particularly in the top-right and middle-right areas of the plot,\n",
    "\n",
    "indicating that these points are quite different from the rest of the data in terms of the principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the NumPy array to a DataFrame and assign column names\n",
    "df_pca = pd.DataFrame(transform_pca, columns=['PC1', 'PC2'])\n",
    "\n",
    "# Display the DataFrame\n",
    "df_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the PCA components with the original DataFrame\n",
    "df = pd.concat([df, df_pca], axis=1)\n",
    "\n",
    "# Display the merged DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply K-means clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "clusters = kmeans.fit_predict(transform_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the clusters on the 2D PCA projection\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(transform_pca[:, 0], transform_pca[:, 1], c=clusters, cmap='viridis', edgecolor='k', s=50)\n",
    "plt.title('K-means Clustering on 2D PCA Projection')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cluster'] = clusters\n",
    "\n",
    "# Calculate the centroids of the clusters\n",
    "centroids = df.groupby('Cluster').mean()\n",
    "\n",
    "# Summarize the clusters by original features\n",
    "cluster_summary = df.groupby('Cluster').agg(['mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids.iloc[:, :4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster 0 budget\n",
    "\n",
    "Cluster 1 luxury\n",
    "\n",
    "Cluster 2 mid-range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_summary.iloc[:, :-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_summary[('Bedrooms', 'mean')].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrooms_mean = cluster_summary[('Bedrooms', 'mean')].tolist()\n",
    "bedrooms_std = cluster_summary[('Bedrooms', 'std')].tolist()\n",
    "\n",
    "bedrooms_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data from the provided summary\n",
    "clusters = ['Cluster 0', 'Cluster 1', 'Cluster 2']\n",
    "\n",
    "bedrooms_mean = cluster_summary[('Bedrooms', 'mean')].tolist()\n",
    "bedrooms_std = cluster_summary[('Bedrooms', 'std')].tolist()\n",
    "\n",
    "bathrooms_mean = cluster_summary[('Bathrooms', 'mean')].tolist()\n",
    "bathrooms_std = cluster_summary[('Bathrooms', 'std')].tolist()\n",
    "\n",
    "floor_area_mean = cluster_summary[('Floor_area', 'mean')].tolist()\n",
    "floor_area_std = cluster_summary[('Floor_area', 'std')].tolist()\n",
    "\n",
    "price_mean = cluster_summary[('Price_in_taka', 'mean')].tolist()\n",
    "price_std = cluster_summary[('Price_in_taka', 'std')].tolist()\n",
    "\n",
    "# Plotting the means with standard deviations as error bars\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 6))\n",
    "\n",
    "# Bedrooms\n",
    "ax[0, 0].bar(clusters, bedrooms_mean, yerr=bedrooms_std, color='skyblue', capsize=5)\n",
    "ax[0, 0].set_title('Bedrooms')\n",
    "ax[0, 0].set_ylabel('Mean ± Std')\n",
    "ax[0, 0].grid(True)\n",
    "\n",
    "# Bathrooms\n",
    "ax[0, 1].bar(clusters, bathrooms_mean, yerr=bathrooms_std, color='salmon', capsize=5)\n",
    "ax[0, 1].set_title('Bathrooms')\n",
    "ax[0, 1].set_ylabel('Mean ± Std')\n",
    "ax[0, 1].grid(True)\n",
    "\n",
    "# Floor Area\n",
    "ax[1, 0].bar(clusters, floor_area_mean, yerr=floor_area_std, color='lightgreen', capsize=5)\n",
    "ax[1, 0].set_title('Floor Area')\n",
    "ax[1, 0].set_ylabel('Mean ± Std')\n",
    "ax[1, 0].grid(True)\n",
    "\n",
    "# Price in Taka\n",
    "ax[1, 1].bar(clusters, price_mean, yerr=price_std, color='orange', capsize=5)\n",
    "ax[1, 1].set_title('Price in Taka')\n",
    "ax[1, 1].set_ylabel('Mean ± Std')\n",
    "ax[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bedrooms: Cluster 1 has the highest mean with a large standard deviation, indicating a wide range of bedroom counts. Clusters 0 and 2 have smaller means and narrower ranges.\n",
    "\n",
    "Bathrooms: Similar to bedrooms, Cluster 1 also has the highest mean and variability in the number of bathrooms.\n",
    "\n",
    "Floor Area: Cluster 1 properties are significantly larger, with the highest mean floor area and considerable variability. Cluster 0 has the smallest floor areas.\n",
    "\n",
    "Price in Taka: Cluster 1 properties are the most expensive, with a very high mean price and large variation. Cluster 0 has the lowest prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##############################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP(n_components=2,     #For visualization purposes\n",
    "                    random_state=123,    #Controls the randomness of the algorithm\n",
    "                    n_neighbors=700,     #Determines the number of neighboring points\n",
    "                    min_dist=0.9,       #The minimum distance between points\n",
    "                    spread=0.9,         #Controls how far apart points can be\n",
    "                    metric='euclidean') #distance computation ['euclidean', 'minkowski', 'cosine', 'jaccard', 'manhattan', 'correlation']\n",
    "umap_results = reducer.fit_transform(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_df = pd.DataFrame(data=umap_results, columns=['UMAP 1', 'UMAP 2'])\n",
    "# Create a DataFrame with the UMAP results\n",
    "umap_df['Bedrooms'] = df['Bedrooms']\n",
    "umap_df['Bathrooms'] = df['Bathrooms']\n",
    "umap_df['Floor_area'] = df['Floor_area']\n",
    "umap_df['Price_in_taka'] = df['Price_in_taka']\n",
    "umap_df['City'] = df['City']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D Scatter plot\n",
    "fig = px.scatter(umap_df, x='UMAP 1', y='UMAP 2', color='City', title='UMAP of Housing Data by City', hover_data=['Bedrooms', 'Bathrooms', 'Floor_area', 'Price_in_taka'])\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
